@article{doumanoglou2018quality,
  title={Quality of Experience for 3-D Immersive Media Streaming},
  author={Doumanoglou, Alexandros and Griffin, David and Serrano, Javier and Zioulis, Nikolaos and Phan, Truong Khoa and Jim{\'e}nez, David and Zarpalas, Dimitrios and Alvarez, Federico and Rio, Miguel and Daras, Petros},
  journal={IEEE Transactions on Broadcasting},
  volume={64},
  number={2},
  pages={379--391},
  year={2018},
  publisher={IEEE},
  url={10.1109/TBC.2018.2823909},
  abstract={Recent advances in media capture and processing technologies have enabled new forms of true 3D media content that increase the degree of user immersion. The demand for more engaging forms of entertainment means that content distributors and broadcasters need to fine-tune their delivery mechanisms over the Internet as well as develop new models for quantifying and predicting user experience of these new forms of content. In the work described in this paper, we undertake one of the first studies into the QoE of real-time 3D media content streamed to VR headsets for entertainment purposes, in the context of game spectating. Our focus is on tele-immersive media that embed real users within virtual environments of interactive games. A key feature of engaging and realistic experiences in full 3D media environments, is allowing users unrestricted viewpoints. However, this comes at the cost of increased network bandwidth and the need of limiting network effects in order to transmit a realistic, real-time representation of the participants. The visual quality of 3D media is affected by geometry and texture parameters while the temporal aspects of smooth movement and synchronization are affected by lag introduced by network transmission effects. In this study, we investigate varying network conditions for a set of tele-immersive media sessions produced in a range of visual quality levels. Further, we investigate user navigation issues that inhibit free viewpoint VR spectating of live 3D media. After reporting on a study with multiple users we analyze the results and assess the overall QoE with respect to a range of visual quality and latency parameters. We propose a neural network QoE prediction model for 3D media, constructed from a combination of visual and network parameters.}
  url_Paper={http://www.iti.gr/iti/files/document/publications/3D_Immersive_Media.pdf},
}

@article{alexiadis2018fast,
  title={Fast deformable model-based human performance capture and FVV using consumer-grade RGB-D sensors},
  author={Alexiadis, Dimitrios S and Zioulis, Nikolaos and Zarpalas, Dimitrios and Daras, Petros},
  journal={Pattern Recognition},
  volume={79},
  pages={260--278},
  year={2018},
  publisher={Elsevier},
  url={10.1016/j.patcog.2018.02.013},
  abstract={In this paper, a novel end-to-end system for the fast reconstruction of human actor performances into 3D mesh sequences is proposed, using the input from a small set of consumer-grade RGB-Depth sensors. The proposed framework, by offline pre-reconstructing and employing a deformable actor’s 3D model to constrain the on-line reconstruction process, implicitly tracks the human motion. Handling non-rigid deformation of the 3D surface and applying appropriate texture mapping, it finally produces a dynamic sequence of temporally-coherent textured meshes, enabling realistic Free Viewpoint Video (FVV). Given the noisy input from a small set of low-cost sensors, the focus is on the fast (“quick-post”), robust and fully-automatic performance reconstruction. Apart from integrating existing ideas into a complete end-to-end system, which is itself a challenging task, several novel technical advances contribute to the speed, robustness and fidelity of the system, including a layered approach for model-based pose tracking, the definition and use of sophisticated energy functions, parallelizable on the GPU, as well as a new texture mapping scheme. The experimental results on a large number of challenging sequences, and comparisons with model-based and model-free approaches, demonstrate the efficiency of the proposed approach.}
  url_Paper={http://www.iti.gr/iti/files/document/publications/RGB-D_09-03-2018.pdf},
  url_Website={http://vcl.iti.gr/performancecapture/},
  url_Data={http://vcl.iti.gr/dataset/dataset-of-multiple-kinect2-rgb-d-streams/},
  url_Supplementary={http://vcl.iti.gr/vclwordpress/wp-content/uploads/2017/06/Suppl_Main3.pdf},
}

@article{alexiadis2017integrated,
  title={An integrated platform for live 3d human reconstruction and motion capturing},
  author={Alexiadis, Dimitrios S and Chatzitofis, Anargyros and Zioulis, Nikolaos and Zoidi, Olga and Louizis, Georgios and Zarpalas, Dimitrios and Daras, Petros},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  volume={27},
  number={4},
  pages={798--813},
  year={2017},
  publisher={IEEE},
  url={10.1109/TCSVT.2016.2576922},
  abstract={The latest developments in 3D capturing, processing and rendering provide means to unlock novel 3D application pathways. The main elements of an integrated platform, which target Tele-Immersion (TI) and future 3D applications, are described in this paper, addressing the tasks of real-time capturing, robust 3D human shape/appearance reconstruction and skeletonbased motion tracking. More specifically, initially the details of a multiple RGB-D capturing system are given, along with a novel sensors’ calibration method. A robust, fast reconstruction method from multiple RGB-D streams is then proposed, based on an enhanced variation of the volumetric Fourier Transformbased method, parallelized on the GPU, accompanied with an appropriate texture mapping algorithm. On top of that, given the lack of relevant objective evaluation methods, a novel framework is proposed for the quantitative evaluation of realtime 3D reconstruction systems. Finally, a generic, multiple depth streams-based method for accurate real-time human skeleton tracking is proposed. Detailed experimental results with multi-Kinect2 datasets verify the validity of our arguments and the effectiveness of the proposed system and methodologies.},
  url_Paper={http://www.iti.gr/iti/files/document/publications/An%20integrated%20platform%20for%20live%203D%20human.pdf},
  url_Website={http://vcl.iti.gr/dataset/3d-reconstruction-and-skeleton-based-motion-tracking/},
  url_Data={http://vcl.iti.gr/dataset/datasets-of-multiple-kinect2-rgb-d-streams-and-skeleton-tracking/},
  url_Supplementary={http://vcl.iti.gr/vclwordpress/wp-content/uploads/2016/02/Reconstruction_Supplementary_.pdf},
}