@inproceedings{sterzentsenko2019denoising,
  author       = "Vladimiros Sterzentsenko and Leonidas Saroglou and Anargyros Chatzitofis and Spyridon Thermos and Nikolaos Zioulis and Alexandros Doumanoglou and Dimitrios Zarpalas and Petros Daras",
  title        = "Self-Supervised Deep Depth Denoising",
  booktitle    = "ICCV",
  year         = "2019",
  url_Pdf={https://arxiv.org/pdf/1909.01193.pdf},
  url_Website={https://vcl3d.github.io/DeepDepthDenoising/},
}

@inproceedings{zioulis2019spherical,
  author       = "Zioulis, Nikolaos and Karakottas, Antonis and Zarpalas, Dimitris and Alvarez, Federic and Daras, Petros",
  title        = "Spherical View Synthesis for Self-Supervised $360^o$ Depth Estimation",
  booktitle    = "International Conference on 3D Vision (3DV)",
  month        = "September",
  year         = "2019",
  url_Pdf={https://arxiv.org/pdf/1909.08112.pdf},
  url_Website={https://vcl3d.github.io/SphericalViewSynthesis/},
  url_Data={https://vcl3d.github.io/3D60/},
}

@inproceedings{karakottas2019360surface,
  author      = "Karakottas, Antonis and Zioulis, Nikolaos and Samaras, Stamatis and Ataloglou, Dimitrios and Gkitsas, Vasileios and Zarpalas, Dimitrios and Daras, Petros",
  title       = "360 Surface Regression with a Hyper-Sphere Loss",
  booktitle   = "International Conference on 3D Vision",
  month       = "September",
  year        = "2019",
  url_Pdf={https://arxiv.org/pdf/1909.07043.pdf},
  url_Website={https://vcl3d.github.io/HyperSphereSurfaceRegression/},
  url_Data={https://vcl3d.github.io/3D60/},
}

@inproceedings{omnidepth2018eccv,
  title={OmniDepth: Dense Depth Estimation for Indoors Spherical Panoramas.},
  author={Zioulis, Nikolaos and Karakottas, Antonis and Zarpalas, Dimitrios and Daras, Petros},
  booktitle={European Conference on Computer Vision},
  year={2018},
  publisher={Springer},
  abstract={Recent work on depth estimation up to now has only focused on projective images ignoring 360 content which is now increasingly and more easily produced. We show that monocular depth estimation models trained on traditional images produce sub-optimal results on omnidirectional images, showcasing the need for training directly on 360 datasets, which however, are hard to acquire. In this work, we circumvent the challenges associated with acquiring high quality 360 datasets with ground truth depth annotations, by re-using recently released large scale 3D datasets and re-purposing them to 360 via rendering. This dataset, which is considerably larger than similar projective datasets, is publicly offered to the community to enable future research in this direction. We use this dataset to learn in an end-to-end fashion the task of depth estimation from 360 images. We show promising results in our synthesized data as well as in unseen realistic images.},
  url_Pdf={https://arxiv.org/pdf/1807.09620.pdf},
  url_Supplementary={http://vcl.iti.gr/vclNew/wp-content/uploads/2018/07/OmniDepth_paper_supp.pdf},
  url_Website={http://vcl.iti.gr/360-dataset/},
  url_Data={https://vcl3d.github.io/3D60/},
}

@inproceedings{360D2018eccvw,
  title={360D: A dataset and baseline for dense depth estimation from 360 images},
  author={Karakottas, Antonis and Zioulis, Nikolaos and Zarpalas, Dimitrios and Daras, Petros},
  booktitle={European Conference on Computer Vision Workshops, 360 Perception and Interaction},
  year={2018},
  publisher={Springer},
  abstract={We present a baseline for 360 dense depth estimation from a single spherical panorama. We circumvent the unavailability of coupled 360 color and depth image datasets by rendering a high quality 360 dataset from existing 3D datasets. We then train a CNN designed specifically for 360 content in a supervised manner, in order to predict a 360 depth map from a single omnidirectional image in equirectangular format. Quantitative and qualitative results show the need for training directly in 360 instead of relying on traditional 2D CNNs},
  url_Pdf={http://vcl.iti.gr/vclNew/wp-content/uploads/2018/08/360D_ECCV2018_Workshop.pdf},
  url_Website={https://vcl3d.github.io/3D60/}
}

@inproceedings{karakottas2018augmented,
  title={Augmented VR},
  author={Karakottas, Antonis and Papachristou, Alexandros and Doumanoqlou, Alexandros and Zioulis, Nikolaos and Zarpalas, Dimitrios and Daras, Petros},
  booktitle={2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)},
  pages={1--1},
  year={2018},
  organization={IEEE},
  url_Video={https://www.youtube.com/watch?v=7O_TrhtmP5Q}
}

@inproceedings{sterzentsenko2018low,
  title={A low-cost, flexible and portable volumetric capturing system},
  author={Sterzentsenko, Vladimiros and Karakottas, Antonis and Papachristou, Alexandros and Zioulis, Nikolaos and Doumanoglou, Alexandros and Zarpalas, Dimitrios and Daras, Petros},
  booktitle={2018 14th International Conference on Signal-Image Technology \& Internet-Based Systems (SITIS)},
  pages={200--207},
  year={2018},
  organization={IEEE},
  abstract={Multi-view capture systems are complex systems to engineer. They require technical knowledge to install and intricate processes to setup related mainly to the sensors’ spatial alignment (i.e. external calibration). However, with the ongoing developments in new production methods, we are now at a position where the production of high quality realistic 3D assets is possible even with commodity sensors. Nonetheless, the capturing systems developed with these methods are heavily intertwined with the methods themselves, relying on custom solutions and seldom - if not at all - publicly available. In light of this, we design, develop and publicly offer a multi-view capture system based on the latest RGB-D sensor technology. For our system, we develop a portable and easy-to-use external calibration method that greatly reduces the effort and knowledge required, as well as simplify the overall process.},
  url_Pdf={https://www.iti.gr/iti/files/document/publications/low-cost-flexible.pdf},
  url_Website={http://vcl.iti.gr/360-dataset/},
  url_Project={https://github.com/VCL3D/VolumetricCapture},
}

@inproceedings{doumanoglou2018bmsb,
  title={A System Architecture for Live Immersive 3D-Media Transcoding over 5G Networks},
  author={Doumanoglou, Alexandros and Zioulis, Nikolaos and Griffin, David and Serrano, Javier, and Khoa Phan, Truang and Zarpalas, Dimitrios and Jimenez, David and Alvarez, Federic and Rio, Miguel and Daras, Petros},
  booktitle={Workshop on Media delivery innovations using flexible network models in 5G, IEEE International Symposium on Broadband Multimedia Systems and Broadcasting (BMSB18)},
  year={2018},
  organization={IEEE}
}

@inproceedings{doumanoglou2018qomex,
  title={Subjective quality assessment of textured human full-body 3D-reconstructions},
  author={Doumanoglou, Alexandros and Zioulis, Nikolaos and Christakis, Emmanouil and Zarpalas, Dimitrios and Daras, Petros},
  booktitle={International Conference on Quality of Multimedia Experience (QoMEX 2018)},
  year={2018},
  organization={IEEE}
}

@article{papachristoumarkerless,
  title={Markerless Structure-based Multi-sensor Calibration for Free Viewpoint Video Capture},
  author={Papachristou, Alexandros and Zioulis, Nikolaos and Zarpalas, Dimitrios and Daras, Petros},
  booktitle={International Conference on Computer Graphics, Visualization and Computer Vision (WSCG)},  
  year={2018},
  abstract={Free-viewpoint capture technologies have recently started demonstrating impressive results. Being able to capture
human performances in full 3D is a very promising technology for a variety of applications. However, the setup
of the capturing infrastructure is usually expensive and requires trained personnel. In this work we focus on one
practical aspect of setting up a free-viewpoint capturing system, the spatial alignment of the sensors. Our work aims
at simplifying the external calibration process that typically requires significant human intervention and technical
knowledge. Our method uses an easy to assemble structure and unlike similar works, does not rely on markers or
features. Instead, we exploit the a-priori knowledge of the structure’s geometry to establish correspondences for
the little-overlapping viewpoints typically found in free-viewpoint capture setups. These establish an initial sparse
alignment that is then densely optimized. At the same time, our pipeline improves the robustness to assembly
errors, allowing for non-technical users to calibrate multi-sensor setups. Our results showcase the feasibility of our
approach that can make the tedious calibration process easier, and less error-prone.
},
  url_Pdf={https://www.iti.gr/iti/files/document/publications/S05-Markerless%20Structure-based%20Calibration.pdf},  
}

@inproceedings{zioulis2017improving,
  title={Improving Camera Pose Estimation via Temporal EWA Surfel Splatting},
  author={Zioulis, Nikolaos and Papachristou, Alexandros and Zarpalas, Dimitris and Daras, Petros},
  booktitle={Mixed and Augmented Reality (ISMAR), 2017 IEEE International Symposium on},
  pages={1--10},
  year={2017},
  organization={IEEE}
}

@inproceedings{zioulis20163d,
  title={3D tele-immersion platform for interactive immersive experiences between remote users},
  author={Zioulis, Nikolaos and Alexiadis, Dimitrios and Doumanoglou, Alexandros and Louizis, Georgios and Apostolakis, Konstantinos and Zarpalas, Dimitrios and Daras, Petros},
  booktitle={Image Processing (ICIP), 2016 IEEE International Conference on},
  pages={365--369},
  year={2016},
  organization={IEEE}
}

@inproceedings{destelle2015multi,
  title={A multi-modal 3D capturing platform for learning and preservation of traditional sports and games},
  author={Destelle, Fran{\c{c}}ois and Ahmadi, Amin and Moran, Kieran and O'Connor, Noel E and Zioulis, Nikolaos and Chatzitofis, Anargyros and Zarpalas, Dimitrios and Daras, Petros and Unzueta, Luis and Goenetxea, Jon and others},
  booktitle={Proceedings of the 23rd ACM international conference on Multimedia},
  pages={747--748},
  year={2015},
  organization={ACM}
}